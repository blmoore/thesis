\documentclass[a4paper,11pt,oneside]{book}

% packages 
\usepackage{arsclassica}    % fancy layout
\usepackage[english]{babel}\addto{\captionsenglish}{\renewcommand{\bibname}{References}}
\usepackage{caption}         % figure captions
\usepackage[square,numbers,super,sort&compress]{natbib}  % bibliography style
\usepackage[cc]{titlepic}    % enable logo on title page
\usepackage{graphicx}       % logo related

\usepackage{standalone}

% bibliography
\bibliographystyle{../thesis}

% title setup
\title{ \vspace{3in} Unravelling higher order genome organisation {\small [working
    title]} \\ \vspace{2em} {\large {\bf Results 2} Predictive modelling } }
\author{Benjamin L. Moore}
\titlepic{\vspace{2.2in} \includegraphics[width=\textwidth]{/Users/benmoore/hvl/1yrReport/figs/igmm.png}}

\begin{document}

\maketitle

\chapter{Integrative modelling as a tool to explore biological systems}
\vspace{2em}

\section{Introduction}
Large-scale chromatin data has recently been produced by multiple
consortia, most notably the ENCODE\cite{Gerstein2012} and NIH
Roadmap Epigenomics\cite{Bernstein2010} projects. The breadth and depth of this new
data offers unprecedented opportunities to further our understanding
regarding the fundamental biology of the chromatin landscape. While many histone
modifications can now be quantified experimentally,\cite{Nikolov2012, Sajan2012, Ernst2011} an integrated
understanding of general mechanisms underlying the cause or effect of
these marks lags behind. A 2011 opinion piece asked
the question ``Histone modification: cause or
cog?''\cite{Henikoff2011} and speculated that nucleosome modifications
could be by-products of transcription machinery, as opposed to
the ``histone code'' hypothesis which suggests that histone
modifications are placed to direct alterations in chromatin
state. This latter hypothesis is often tacitly invoked in the
chromatin literature, wherein a mark may be described as
``repressive'' or ``activating'' despite only the observation of a
correlative relationship.\cite{Henikoff2011} Similarly, the interplay
between locus-level factors and higher-order organisation of
chromatin, while known the be an important factor in
transcription, remains poorly understood mechanisatically.\cite{Li2011} 
% Colin's sentence:
However, the recent flood of data from high throughput sequencing technologies have provided fascinating new glimpses of the ways chromatin and transcription are functionally related.\\

Recent studies have shown convincingly that local chromatin state
measurements can accurately predict expression levels of genes on a
genome-wide basis. Tippmann \emph{et
  al.},\cite{Tippmann2012} designed a linear model to predict
steady-state mRNA levels in mouse (\emph{Mus musculus}) embryonic stem
cells based on just four predictors: 3 histone modifications
(H3K36me3, H3K4me2 and H3K27me3) and
Pol-II occupancy. Remarkably, the linear model was found to explain
84.6\% of an estimated 91\% maximal variance that could be explained
(as calculated through a detailed determination of noise). An additional
finding of this study was that mRNA half-life and microRNA mediated
transcript degradation both had relatively minor influence on
steady-state mRNA levels, with the authors concluding that``the lion's
share of regulatory contribution is at the level of mRNA synthesis and
predictable from chromatin alone.''\cite{Tippmann2012} An independent
study used a similar regression modelling approach to chromatin
and transcription factor data and again
concluded that models built with histone modifications and chromatin
accessibility data were almost as accurate as those which also
included binding data for 12 transcription factors.\cite{McLeay2012a} \\

A recent key study from the ENCODE consortium used chromatin (ChIP-seq) datasets to predict gene expression in a range
of cell types as measured by a variety of experimental techniques.\cite{Dong2012} The authors here developed a
two-stage model which first attempts to classify each transcription
start site (TSS) into an `on' or `off' state using a powerful ensemble
classifier technique called Random Forests (RF). The second stage of the
model used the same range of histone modifications as regressors in a
simple linear modelling framework to quantify predicted
expression. This approach proved very successful, producing a
median Pearson correlation coefficient ($r$) between predicted and
empirical expression levels using 10-fold cross-validation of
$0.83$ across all cell lines and expression level
technologies.\cite{Dong2012} Additionally, this study highlighted cap
analysis of gene expression (CAGE) as the 
technology, relative to RNA-Seq and RNA-PET, which produced the most
predictable expression response. CAGE uses 5$^\prime$ capped transcripts to
generate short, specific tags which precisely identify TSS positions as well as
quantifying the abundance of a given transcript.\cite{Shiraki2003, Kodzius2006}\\

These recent publications highlight the importance and relevance of
advancing our understanding of chromatin biology through a model-based
approach. Each of these existing models however, treats expression
levels as stationary outcome in each cell type and ignores any temporal
dynamics. The huge amount of novel timecourse CAGE data 
produced by the FANTOM5 consortium\cite{fantom5} puts us in an ideal
position to investigate how chromatin influences transcription beyond a
simple single-point response and move towards a more complete
understanding of the drivers of transcriptional flux.



\section{Reproducing Dong \emph{et al.} }

Following on from Dong \emph{et al.},\cite{Dong2012} I first
reimplemented the published ENCODE modelling framework to ensure I could
replicate their results. In doing so I was also able to analyse the
strengths and caveats of their approach; surprisingly the two-step classification
then regression (firstly assessing a gene as `on' or `off' and then
predicting its expression level) added little additional accuracy relative to a simple
linear regression model 
(Fig. \ref{fig:TwoStepvsSimple}). \\

\begin{figure}
\begin{center}
\includegraphics[width=.7\textwidth]{figs/improvedDongPlot.pdf}
\captionsetup{width=\textwidth}
\caption{Comparison of classification-regression model (\emph{upper})
  with simple linear regression model (\emph{lower}) recalculated following Dong
  \emph{et al.}\cite{Dong2012} Scatterplots of predicted against empirical
  $\log_2$ reads per million (RPM) expression values for both methods are shown (\emph{left})
  along with frequency distributions of predicted and observed
  expression levels (\emph{right}). Scatterplots are annotated with
  Pearson's correlation coefficient (\emph{r}) and the root mean
  squared error (RMSE); the black trendlines describe $y =
  x$. Following 10-fold cross validation, overall correlation
  coefficients were: linear model $0.87 \pm 1.77 \times 10^{-5} $;
  Two-step model $0.872 \pm 9.89 \times 10^{-5} $. All correlations
  were statistically significant with $p < 1 \times 10^{-15}$ under the assumption of a
  $t$-distributed $r$ with $d.f. = 7998$.
}\label{fig:TwoStepvsSimple}
\end{center}
\end{figure} 

An innovative element of Dong \emph{et al.}'s modelling approach is the `bestbin' method of matching
chromatin measurements to the expression of a given TSS. This strategy
first bins normalised signal intensities into $40 \times 100$ bp bins
encompassing 4 kbp around the TSS, and adds an additional bin representing the remaining
gene body. Then the correlation between
the signal of a given mark and the expression of a TSS across all
genes is measured --- the bin producing the highest correlation is
designated as the `bestbin' and that bin's normalised ChIP-seq signal intensity in then
taken forward for the full model. This was shown to raise
the correlation (between predicted and observed expression) by 0.1 in
the simple regression model, an increase in accuracy of almost $13\%$,
relative to simply taking the average value across all
bins.\cite{Dong2012} \\

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{figs/Dong_relImp_Horiz.pdf}
\captionsetup{width=.9\textwidth}
\caption{Relative importance metrics for variables in both the
  classification (\emph{left}) and regression (\emph{right}) stages of
  my reimplementation of Dong \emph{et al.}'s two-step
  model.\cite{Dong2012} The additional variable `ReplicationTiming'
  shows the influence of $\log_2 (early/late)$ replication timing ratio measured in the BG02 ESC cell type;\cite{Ryba2010}
  H1 hESC data was not available but these higher-order measurements
  appear to be largely conserved across cell-types.\cite{Chambers2012}
  For details of CAR $R^2$ decomposition, see Zuber and Strimmer (2010).\cite{Zuber2011}
}\label{fig:relimp}
\end{center} 
\end{figure} 

I attempted to improve the accuracy of predicted expression values
produced by Dong \emph{et al.} through two methods: increasing the number of informative
regressors and increasing the complexity of the model by adding
interaction terms and/or non-linear components. While Dong \emph{et
  al.} included broad coverage of different histone modifications,
they did not investigate the impact of higher-order
chromatin data. For this reason, I matched the TSS positions used in
Dong \emph{et al.} with previously-published genome-wide replication
timing ratios measured in BG02 ESCs.\cite{Ryba2010} I then used these values as an additional
regressor in both the two-step classification regression model and the
simple linear model but saw no significant improvement in either
model's accuracy. The reasons for this are likely that the 
data were relatively low-resolution (1 megabase blocks), from a
imperfectly matched cell line and also that
the Dong \emph{et al.} model is already achieving such accurate
results that they must already be accounting for most of the maximal
explainable variance in gene expression given experimental and
biological noise. With this in mind, additional regressors would be
expected to yield diminishing returns. However, on closer examination,
the replication timing data
appeared only slightly more informative than the control ChIP-seq input
measurements when evaluated with relative importance metrics
(Fig. \ref{fig:relimp}), implying that large-scale chromatin domains
and long range interactions
do not have significant influence on the expression of the genes resident within them. It would
be of interest to investigate this further should more detailed higher order
data become available. For example Hi-C interaction matrices have been
calculated in the H1 cell line\cite{Dixon2012} and these could be
compressed to principle component eigenvectors as has been done with
other cell lines.\cite{Lieberman2011}

\section{Modelling FANTOM5 CAGE timecourse data}
Using unpublished FANTOM5 data and the approach established above, I next attempted to model gene
expression at timepoint zero ($t_0$) of a differentiation timecourse of Human
H1 embryonic stem cells (H1 hESC) to CD34+ hematopoietic stem
cells. \\

% How did I do this?:
% 1) Take robustly mapped CAGE clusters -> Entrez Gene IDs
% 2) Select the strongest expressed CAGE cluster
% 3) Either a) use this as a TSS or b) map to closest annotated TSS
The first stage of the analysis was to map each CAGE cluster to a
representative TSS. FANTOM5 robust gene mapping\cite{fantom5}
provided corresponding Entrez Gene IDs for gene-associated CAGE
clusters, and I selected the most expressed cluster to represent the
expression level of its mapped gene. I then compared these to Ensembl
TSS annotations (v69) and
discarded those tag clusters centered on a point $>50$ bp from an annotated
TSS associated with the mapped Entrez Gene ID, thereby removing enhancers and other non-genic transcribed
regions. \\

Next I retrieved a number of genome-wide histone modification datasets
from the ENCODE and
NIH Roadmap consortia which were measured in H1 hESC cells, taking these to be
reflections of the chromatin state $t_0$. I implemented the
previously-described `bestbin' strategy\cite{Dong2012} to objectively
select the most-correlated binned signal for each chromatinH1 hESC
mark. Additionally, I analysed the stability of chosen bestbins by
calculating them on 200 sets of 1000 randomly selected TSS samples (with each sample
representing approximately $8\%$ of the dataset) and the result is
shown in Figure \ref{fig:bestbin}. \\

\begin{figure}
\begin{center} 
\includegraphics[width=.9\textwidth]{figs/bestbinSummary.pdf}
\captionsetup{width=\textwidth}
\caption{Distributions of bestbin locations relative to the
  TSS. Bestbins were selected for normalised ChIP-seq
  signal intensities for 10 histone marks, the
  H2A.Z histone variant, Hdac6 histone deacetylase, Dnase
  hypersensitivity and a ChIP-seq input chromatin control. Bins analysed
  extended 2 Kb flanking the TSS, but more distal bins were
  never selected and hence are not shown. `Whole gene` represents the
  averaged signal intensity from TSS to transcript end site, as
  defined by Ensembl Genes v69.
}\label{fig:bestbin}
\end{center}
\end{figure} 

This result shows that bestbin selections are often consistent, indicating there are predictably informative regions
relative to a TSS for each chromatin factor (Fig. \ref{fig:bestbin}). Furthermore, the selected
bestbins match known biological mechanisms; for example the H3K36me3
mark's bestbin is consistently the whole gene measurement and this
mark is known to be enriched in actively transcribed
exons.\cite{Tippmann2012, Kolasinska-Zwierz2009, Schaft2003} \\

Having matched a variety of genome-wide H1 hESC chromatin datasets
to the FANTOM5 timecourse expression data, I then built a regression
model using a Random Forest (RF) approach.\cite{Breiman2001} This method outperforms a simple
linear model in my initial comparisons and is able to capture non-linear relationships as well
as interactions without them being explicitly specified.\cite{Diaz2006} \\

\begin{figure}
\begin{center} 
\includegraphics[width=.9\textwidth]{figs/RandomForest_10CV_50d.pdf}
\captionsetup{width=\textwidth} 
\caption{Evaluation of RF model predictions ($x$-axis) against an independent
  test set ($y$-axis). The distributions of predicted and empirical
  expression values are shown opposite their
  respective axes. Pearson's correlation coefficient ($r$) and the root
  mean-squared error (RMSE) are also shown (\emph{inset}).
}\label{fig:model}
\end{center} 
\end{figure} 

Figure \ref{fig:model} shows the resulting predictions of a
preliminary RF model against the actual recorded expression over a
test set of approximately 11000 TSS. This model was built with 15
predictors including control ChIP-seq input, though some of these could be
removed without loss of accuracy. The model predictions evluated with
10-fold cross validation show a
significant correlation with measured CAGE levels ($ r = 0.845\pm
1 \times 10^{-4}$; $t_{10868} = 164.4$,
$p < 2 \times 10^{-15}$), and the model is able to explain around
$71\%$ of the variance in the expression response (for comparison a
linear model resulted in $r = 0.825 \pm 3.2 \times 10^{-5}$; $t_{10868} = 152.2$,
$p < 2 \times 10^{-15}$). \\

This result is worse than that of Dong \emph{et al.}
who achieved cross-validated correlation coefficients of up to $0.9$,
but it is roughly equal to their median test set correlation of
$0.83$.\cite{Dong2012} The RMSEs, when normalised by the range of
observed values, compare more favourably ($0.11$, compared with Dong \emph{et al.}'s: $0.14$). A possible explanation for this decrease in
accuracy is that while both chromatin data and expression timecourse
were measured in H1 hESC cells, the experiments took place at
different institutes and likely using differing protocols and cell cultures. For comparison, a previous study using chromatin
measurements from a number of different sources to predict expression
in a matched cell-type reported a predictive correlation of 0.77.\cite{Karlic2010} Additionally, Dong \emph{et al.} implemented a pseudocount
optimisation step whereby an additional count added to each binned signal
intensity prior to log transformation was optimised to maximise
expression correlation. In the model presented above, a fixed
psuedocount of $1$ was used to avoid introducing positive bias towards
higher correlation. Another difference between the two approaches is
our use of a single-step model; Dong \emph{et al.} found a small
increase in correlation using their classification-regression approach
but with the model implemented herein (Fig. \ref{fig:model}) this approach gave no obvious advantage (for
example, $r
= 0.834 \pm 0.007$, $\textrm{RMSE} = 1.77$ when applied to the same test and
training data used in Fig. \ref{fig:model}). \\

Having built a reasonable model of $t_0$ expression, the next stage of
this preliminary analysis was to consider successive timepoints. In the
available CD34+ differentiation dataset, this consisted of expression
data recorded at three
timepoints (days 0, 3 and 9---hereafter $t_0$, $t_3$ and $t_9$
respectively). However genome-wide expression
was highly correlated between each of these timepoints (Pearson correlation coefficients: $t_0, t_3 = 0.911; ~t_0,t_9 =
0.913; ~t_3,t_9 = 0.977$), and this high correlation meant that the
genome-wide model performed essentially equally well regardless of the
expression timepoint it was trained or tested on. In future analyses, higher-resolution timecourses may offer
more interesting variation or alternatively genes that remain invariant
throughout the timecourse could be filtered out of the dataset. 


\subsection{Dissecting the  \emph{best bin} approach}

\section{Modelling higher order chromatin}

\subsection{Cross-application}

\subsection{Variable importance}


% figure showing e.g. how individual var regresses against eigen (Egr1compare.pdf)

\subsection{Correlating input features}

\ifstandalone
\begin{small}
\bibliography{/Users/benmoore/Documents/library,/Users/benmoore/Documents/customrefs}
\end{small}
\fi

\end{document}
