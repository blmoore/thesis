\documentclass[a4paper,10pt,oneside]{book}

% packages 
\usepackage{arsclassica}    % fancy layout
\usepackage[english]{babel}\addto{\captionsenglish}{\renewcommand{\bibname}{References}}
\usepackage{caption}         % figure captions
\usepackage[square,numbers,super,sort&compress]{natbib}  % bibliography style
\usepackage[cc]{titlepic}    % enable logo on title page
\usepackage{graphicx}       % logo related

\usepackage{bm} % bold math
\usepackage{amsmath} % underset
\usepackage{hyperref} % urls
\usepackage{standalone}

% attempt to adj. typography: old style numbers, drop below line
%\usepackage[% 
%  rm={oldstyle=false},% 
%  sf={oldstyle=false},% 
%  tt={oldstyle=false,proportional=false,monowidth}% 
%]{libertine} 

% bibliography
\bibliographystyle{../thesis}

% title setup
\title{ \vspace{3in} Unravelling higher order genome organisation {\small [working
    title]} \\ \vspace{2em} {\large {\bf Methods section}} }
\author{Benjamin L. Moore}
\titlepic{\vspace{2.2in} \includegraphics[width=\textwidth]{/Users/benmoore/hvl/1yrReport/figs/igmm.png}}

\begin{document}

\maketitle

\chapter{Methods}

\section{Hi-C data}

\subsection{Mapping}

Raw Hi-C reads were downloaded from published datasets (Table \ref{hictable}) through
the Gene Expression Omnibus (GEO)\citep{Barrett2013} or the Short Read Archive (SRA)\citep{Leinonen2011a} with identifiers:
GSE35156 (H1 hESC), GSE18199 (K562) and SRX030113 (GM12878). These
paired reads were mapped independently to a reference genome: hg19/GRCh37 for human data, and mm10/GRCm38 for mouse. 

\begin{table}
\centering
\caption{{\bf Public Hi-C data used in this work.} }
\label{hictable}
\begin{tabular}{lllr}
{\bf Cell line} & {\bf Total reads} & {\bf Accession} & {\bf Citation}\\
\hline
Gm12878 & 31$\times10^{6}$ & \href{http://www.ncbi.nlm.nih.gov/sra/SRX030113[accn]}{SRX030113} & \citenum{Kalhor2012} \\
H1 hESC & 331$\times10^{6}$ & \href{http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE35156}{GSE35156} &\citenum{Dixon2012} \\
K562 & 36$\times10^{6}$ &  \href{http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE18199}{GSE18199}  & \citenum{Lieberman2009} \\
\hline
Cortex & 373$\times10^{6}$ & \href{http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE35156}{GSE35156}& \citenum{Dixon2012} \\
mESC & 476$\times10^{6}$ & \href{http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE35156}{GSE35156}&\citenum{Dixon2012} \\
\hline
IMR90 & 355$\times10^{6}$ &\href{http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE35156}{GSE35156} &\citenum{Dixon2012} 
\end{tabular}
\end{table}

Mapping was performed using the \texttt{hiclib} software
package\citep{Imakaev2012} and \texttt{bowtie2}\citep{Langmead2012} with
the \texttt{-{}-very-sensitive} flag. An iterative mapping approach was used to maximise the number of aligning fragments.\cite{Imakaev2012} Each fragment end was aligned first using short terminal sub-sequences. Those unmapped or with ambiguous mapping were then taken forward into the next iteration and extended until the entire fragment end had been aligned. Those remaining pairs with one or more unmapped ends were discarded.

\subsection{Filtering}

After mapping, interactions are first aggregated into restriction fragments then by regular binning of various resolutions (particularly 40 kb, 100 kb and 1 Mb). Several filters were applied at this stage, with the following cases removed:\cite{Imakaev2012} 
\begin{itemize}
\item Reads directly adjacent to a restriction enzyme site (within 5 bp)
\item Identical read pairs (presumed PCR duplicates)
\item Very large restriction fragments ($>100$ kb) which are likely from a repetitive or poorly-assembled region
\item Extremely over-represented fragments (top $.05\%$) which may throw-off eigenvector derivation
\end{itemize}

\subsection{Correction}

Iterative correction and eigenvector expansion (ICE) is an approach to normalisation and processing Hi-C data, implemented as software library written in \texttt{python}.\citep{Imakaev2012} The iterative correction algorithm performs matrix balancing with the aim of generating a doubly stochastic matrix from raw interaction counts. That is, such that symmetric matrix $\mathbf{A}$ has both row and columns of equal sum. In practice, this effectively enforces "equal visibility" of each fragment, correcting for previously-described biases in interaction recovery such as GC-content and fragment length\cite{Yaffe2011} but without explicitly modelling these latent variables. This procedure is thus converting actual interaction counts into normalised interaction frequencies (IF), and to relative rather than absolute quantities. Scaling of IFs permits comparison of Hi-C experiments with very different sequencing depths (as is the case in this work, see Table \ref{hictable}).

\subsection{Eigenvector calculation}
Additional functionality provided by ICE is the eigenvector expansion of normalised contact maps. Eigenvectors from observed/expected matrices were chosen for consistency with Lieberman Aiden \emph{et al.},\cite{Lieberman2009} as opposed to the related eigenvectors calculated in Imakaev \emph{et al.}\cite{Imakaev2012} form the corrected maps alone. The details of this procedure are described in section \ref{sec:compartments}. Briefly, observed contacts (O) are divided by an expected matrix (E) which is generated by averaging the super- and sub-diagonals of the O matrix. That is, the E matrix gives the expected value of interactions at a given distance.

Importantly, the first two principle components (PCs) were calculated, and that with the highest absolute Spearman correlation with GC content is taken to reflect A/B compartmentalisation. PC eigenvectors were then orientated to positively correlate with GC, ensuring positive values reflected A compartments and negative values B compartments. Another subtlety is the calculation of eigenvectors per chromosome arm as opposed to per chromosome, this prevents issues with some meta- and submetacentric chromosomes where the first principle component indicated chromosome arms.\cite{Lieberman2009, Imakaev2012} Eigenvector expansion was performed on both 1 Mb and 100 kb matrices, below these resolutions results became less stable, and it has been shown that eigenvectors at

\section{ENCODE features}\label{locus-level-features}

Genome-wide ChIP-seq datasets for: 22 DNA binding proteins and 10
histone marks were made available by the ENCODE
consortium\citep{Dunham2012, Boyle2014} along with DNase I
hypersensitivity and H2A.z occupancy, for each of the Tier 1 ENCODE cell
lines used in this work: H1 hESC, K562 and GM12878. These data were
pre-processed using MACSv2\citep{Zhang2008} to produce fold-change
relative to input chromatin. GC content was also calculated and used in
the featureset.

%\begin{table}[h]
%\centering
%\caption{ ChIP-seq and other public datasets used in this work. }
%\label{my-label}
%\begin{tabular}{llr}
%  & {\bf Description} & {\bf Citation}\\
%\hline
%% histone modifications
%H3K27ac&&\\
%H3K27me3&&\\
%H3K36me3&&\\
%H3K4me1&&\\
%H3K4me2&&\\ 
%H3K4me3&&\\
%H3K79me2&&\\
%H3K9ac&&\\
%H3K9me3&&\\
%H4K20me1&&\\
%
%\hline
%% DNA binding proteins
%ATF3 & & \\
%CEBPB&&\\
%CHD1&&\\
%CHD2&&\\
%CMYC&&\\
%CTCF&&\\
%EGR1&&\\
%EZH2&&\\
%GABP&&\\
%JUND&&\\
%MAX&&\\
%MXI1&&\\
%NRSF&&\\
%POL2&&\\
%P300&&\\
%RAD21&&\\
%SIX5&&\\
%SP1&&\\
%TAF1&&\\
%TBP&&\\
%YY1&&\\
%ZNF143&&\\
%
%\hline
%% GC
%
%GC & Base composition calculated from \texttt{hg19} sequence & This work \\
%
%\end{tabular}
%\end{table}

\subsection{Clustering input features}

To quantify collinearity of input features, correlation matrices built from genome-wide vectors of input feature measures were build and hierarchicaly clustered. The "significance" of observed clustering was assessed using sub- and super-sampled bootstrapping, with stable clusters deemed significant. The \texttt{pvclust} R package

\section{Modelling}\label{modelling}

\subsection{Random Forest}\label{sec:rf}

\begin{figure}
\begin{center}
\includegraphics[width=\textwidth]{figs/randforests.pdf}
\captionsetup{width=\textwidth}
\caption{ {\bf Steps in the Hi-C assay. } 
  Schematic of the Hi-C experimental procedure as described in Lieberman Aiden \emph{et al.}\cite{Lieberman2009}
}\label{fig:hicmethod}
\end{center}
\end{figure} 

Random Forest (RF) regression,\cite{Breiman2001a}  was used
as implemented in the R package \texttt{randomForest}.\cite{Liaw2002}
The RF algorithm makes use of a collective of regression trees (size $ntrees$), each built from a
bootstrapped sample of the training set. In growing each tree, a small
number of variables ($mtry$) is tested at each bifurcation node, and that which minimises the
variance in child node subsets is selected at a specific
threshold. Having trained a group of trees, these can then be used as
predictive tools by inputting a vector of features to each tree and
averaging the output leaf node value across the forest. RF regression
was used as it is known to be one of the most powerful regression
methods developed to date,\cite{Svetnik2003, Cutler2007} typically
providing low bias and low variance predictions without the need for
variable selection.\cite{Diaz2006, Dasgupta2012}
Additionally the RF method represents an example of ``algorithmic
modelling''\cite{Breiman2001b} in that it makes no assumptions about the
underlying data model.
Parameters of $mtry = \frac{n}{3}$ (where $n$ is the number of input features) and $ntrees =
200$ were assumed as they are known to be
largely insensitive;\cite{Dasgupta2012, Hastie2001} this was verified
with the dataset used in this work (Fig. \ref{fig:rfparam}). \\

Variable importance within Random Forest regression models was measured
using mean decrease in accuracy in the out-of-bag (OOB) sample. This
represents the average difference (over the forest) between the accuracy
of a tree with permuted and unpermuted versions of a given variable, in
units of mean squared error (MSE).\citep{Cutler2007, Dasgupta2012}

\subsection{Model performance}\label{model-performance}

The effectiveness of the modelling approach was measured by four
different metrics. Prediction accuracy was assessed by the Pearson
correlation coefficient between the predicted and observed eigenvectors
(determined by 10-fold cross-validation), and the root mean-squared
error (RMSE) of the same data. Classification error, when predictions
where thresholded into $A \geq 0; B < 0$, was also calculated using
accuracy (\% correct classifications or True Positives) and area under
the receiver operating characteristic (AUROC) curve. Together these give
a comprehensive overview of the model performance, both in terms of
regression accuracy of the continuous eigenvector, and in how that same
model could be used to label discrete chromatin compartments.

For cross-application of cell type specific models, a single Random
Forest regression model was learned from all 1 Mb bins for a given cell
type. This was then used to predict all bins from each of the other two
cell types.

\subsection{Other modelling approaches}
 
Linear regression was used as a baseline for comparison with more complicated approaches such as Random Forest. If the same modelling accuracy could be achieved with simple multiple linear regression, this would be a faster and more interpretable modelling framework.

Partial least squares regression was also used to model compartment profiles. This method is well-suited to highly correlated inputs.

\subsection{Graphical lasso}
Regularised models made use of the Graphical LASSO\cite{Friedman2008}
(least absolute shrinkage and selection operator) as a method of
$L_1$-norm based
regularisation, implemented via the \texttt{glasso} R package. The
graphical lasso provides tuneable regularisation which is
capable of feature selection via minimising regression parameters to
0. It was chosen in this case due to the multicollinearity of the
featureset, the algorithm's fast speed of
execution and the intuitiveness a graphical model
presents.\cite{Friedman2008} \\

More specifically, the graphical lasso regulates the number of 0s in
the inverse covariance matrix, $\bm{\Theta}=\bm{\Sigma}^{-1}$, also known as the
precision matrix. Then if element $\theta_{ij}=0$, the variables $X_i$ and $X_j$ can be said to be
conditionally independent, given the remaining
variables.\cite{Mazumder2012} The algorithm minimises a negative
log-likelihood (Eqn. \ref{eq:glasso}\cite{Mazumder2012}) given the tuning parameter $\lambda$, which was tuned
in this case to leave a small number of variables ($<10$)
directly dependent on the eigenvector data. \\
\begin{equation} \label{eq:glasso}
\underset{\bm{\Theta}\prec\bm{0}}{\mathrm{minimise}}~f(\bm{\Theta}) :=
-\log\det(\bm{\Theta}) + \mathrm{tr}(\bm{\mathrm{S}\Theta}) + \lambda
\lVert\bm{\Theta}\rVert_1
\end{equation}


\section{Variable regions}\label{variable-regions}

\subsection{Stratification by
variability}\label{stratification-by-variability}

Median absolute deviation (MAD) was chosen as a robust measure of the
variability in a given 1 Mb block between the three primary cell types
used in this work: H1, K562 and GM12878. Blocks were ranked by this
measure and split into thirds that represented ``low'' variability (the
third of blocks with the lowest MAD), ``mid'' and ``high'' variability.
Each subgroup was then independently modelled using the
previously-described Random Forest approach.

``Flipped'' regions are those whose compartment state differs in one
cell type relative to the other two. For example, if a 1 Mb bin was
classified as ``open'' in H1 hESC and ``closed'' in both K562 and
GM12878, this is said to be a ``flipped'' compartment (to open).

\subsection{Enhancer enrichment}\label{enhancer-enrichment}

Enhancer annotations were collected from the ChromHMM / SegWay combined
annotations in each cell type.\citep{Hoffman2013} Enhancers were
considered ``shared'' if there was an overlapping enhancer annotation in
either of the two other cell types, and labelled as ``tissue-specific''
otherwise.

This was repeated for other chromatin states.

\section{Boundaries}\label{boundaries}

\subsection{TADs}\label{tads}

TAD boundaries were called using the software provided in
\citet{Dixon2012} using their recommended parameters. For the generation
of boundary profiles, the same parameters were used: input features were
averaged into 40 kb bins spanning $\pm500$ kb from the boundary centre.

To align boundaries between cells \ldots

\subsection{Compartments}\label{sec:compartments}

Compartment boundaries were called by first training a two-state hidden
Markov model (HMM) on the compartment eigenvector and then using the
Viterbi algorithm to predict the most likely state sequence that
produced the observed values. The point at which transitions occurred
between states was taken as a boundary which was then extended $\pm 1.5$
Mb to give a 3 Mb window in which a boundary was though to occur.

To test for the enrichment or depletion of a chromatin feature over a
given boundary, a two tailed Mann-Whitney test was used to compare the
boundary bin with the ten outermost bins of the window (5 from either
side). The significance level at $\alpha = 0.01$ was then
Bonferonni-adjusted for multiple testing correction, and results with
\emph{p}-values exceeding this threshold were deemed significantly
enriched or depleted at a given boundary.

\subsection{MetaTADs}\label{sec:m-metatad}

\section{Giemsa band comparison}\label{giemsa-band-comparison}

Cytogenic band data and Giemsa stain results were downloaded from the
UCSC genome browser (table \texttt{cytoBandIdeo}). The genomic
co-ordinates are an approximation of cytogenic band data inferred from a
large number of FISH experiments.\citep{Furey2003}

To compare G-band boundaries with our compartment data, we allowed for a
$\pm 500$ kb inaccuracy in G-band boundary. For each G-band boundary,
the minimum absolute distance to any compartment or TAD boundary was
calculated for each cell type. To generate a null model, \ldots

\section{Nuclear positioning}
Previously published data  on chromosome positioning preference within
the nucleus was used to label each chromosome as ``inner'', ``middle''
or ``outer''.\cite{Boyle2001} Chromosomes whose DAPI hybridisation
signals were significantly enriched ($p\leq 2\times10^{-2}$) in the inner nuclear shell, as
defined by Boyle \emph{et al.}\cite{Boyle2001}, made up the ``inner''
group and included chromosomes 1 and 16. Similarly the ``outer'' group
had enriched signals ($p\leq 5\times10^{-3}$) in the outer shell relative to the inner nuclear
shell and included chromosomes 2, 3, 11-13 and 18. The remaining
chromosomes in our filtered dataset, 6, 14 and 15, were assigned to
the ``middle'' group and showed no significant to either inner or
outer nuclear shells ($p \geq 0.1$).\cite{Boyle2001} The significance
of the difference in distribution of eigenvectors in the inner
versus outer shell was determined by a one-sided Kolmogorov-Smirnov (K-S)
test, with the alternative hypothesis that the empirical cumulative
density function of the inner chromosome eigenvectors $F_{inner}$
is greater-than or equal-to $F_{outer}$. This chromosomal positioning data was measured in lymphoblastoid
cells though nuclear architecture is though to be largely conserved
between cell types\cite{Chambers2013, DeWit2013} and even higher primates.\cite{Tanabe2002}

\ifstandalone
\begin{small}
\bibliography{/Users/benmoore/Documents/library,/Users/benmoore/Documents/customrefs}
\end{small}
\fi

\end{document}
